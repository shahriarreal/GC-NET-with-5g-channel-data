{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Yi/Desktop/channel-cla/Train/0/\n",
      "C:/Users/Yi/Desktop/channel-cla/Train/1/\n"
     ]
    }
   ],
   "source": [
    "# Libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os,sys\n",
    "from keras.models import Model\n",
    "import csv\n",
    "\n",
    "# Reading the input images and putting them into a numpy array\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "height = 128\n",
    "width = 16\n",
    "channels = 1\n",
    "classes = 2\n",
    "n_inputs = height * width*channels\n",
    "\n",
    "for i in range(classes) :\n",
    "    path = \"C:/Users/Yi/Desktop/channel-cla/Train/{0}/\".format(i)\n",
    "    print(path)\n",
    "    Class=os.listdir(path)\n",
    "    # for a in Class:\n",
    "    try:\n",
    "        # image=cv2.imread(path+a)\n",
    "        file_name = os.path.join(path, 'pdata{0}_128x16x1000_2dB.csv'.format(i+1))\n",
    "        with open(file_name) as f:\n",
    "            reader = csv.reader(f)\n",
    "            csv_file = list(reader)\n",
    "        csv_file_mat = np.array(csv_file)\n",
    "        csv_shape = np.shape(csv_file_mat)\n",
    "        csv_file_mat = np.reshape(csv_file_mat, (csv_shape[0], csv_shape[1], channels))\n",
    "        num_obj = int(csv_shape[0] / 128)\n",
    "        for idx in range(num_obj):\n",
    "            obj = csv_file_mat[int(128 * idx) : int(128 * (idx + 1))]\n",
    "            # print(type(obj))\n",
    "            # print(np.shape(obj))\n",
    "            # exit()\n",
    "            # image_from_array = Image.fromarray(image, 'RGB')\n",
    "            # size_image = image_from_array.resize((height, width))\n",
    "            data.append(obj)\n",
    "            labels.append(i)\n",
    "        # print(labels)\n",
    "    except AttributeError:\n",
    "        print(\" \")\n",
    "            \n",
    "Cells=np.array(data)\n",
    "labels=np.array(labels)\n",
    "\n",
    "#Spliting the images into train and validation sets\n",
    "(X_train,X_val)=Cells[(int)(0.2*len(labels)):],Cells[:(int)(0.2*len(labels))]\n",
    "#X_train = X_train.astype('float32')/255 \n",
    "#X_val = X_val.astype('float32')/255\n",
    "(y_train,y_val)=labels[(int)(0.2*len(labels)):],labels[:(int)(0.2*len(labels))]\n",
    "\n",
    "#Randomize the order of the input images\n",
    "s=np.arange(X_train.shape[0])\n",
    "np.random.seed(2)\n",
    "np.random.shuffle(s)\n",
    "X_train=X_train[s]\n",
    "y_train=y_train[s]\n",
    "# print(Cells)\n",
    "# print(labels)\n",
    "# print(data)\n",
    "\n",
    "#Using one hote encoding for the train and validation labels\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, classes)\n",
    "y_val = to_categorical(y_val, classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 128, 16, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 16, 64)  640         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 64, 8, 64)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64, 8, 64)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 8, 64)    36928       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 4, 64)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 4, 64)    0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 4, 64)    36928       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 64)           0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 64)           0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 64)           0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 192)          0           global_average_pooling2d_7[0][0] \n",
      "                                                                 global_average_pooling2d_8[0][0] \n",
      "                                                                 global_average_pooling2d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           12352       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            130         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 86,978\n",
      "Trainable params: 86,978\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/20\n",
      "1600/1600 [==============================] - 17s 11ms/step - loss: 0.6596 - accuracy: 0.6269 - val_loss: 1.0412 - val_accuracy: 0.0025\n",
      "Epoch 2/20\n",
      "1600/1600 [==============================] - 17s 11ms/step - loss: 0.5935 - accuracy: 0.6988 - val_loss: 1.3963 - val_accuracy: 0.0050\n",
      "Epoch 3/20\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 0.3600 - accuracy: 0.8344 - val_loss: 0.8732 - val_accuracy: 0.5100\n",
      "Epoch 4/20\n",
      "1600/1600 [==============================] - 20s 12ms/step - loss: 0.1295 - accuracy: 0.9450 - val_loss: 0.0676 - val_accuracy: 0.9825\n",
      "Epoch 5/20\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 0.0276 - accuracy: 0.9937 - val_loss: 0.0292 - val_accuracy: 0.9875\n",
      "Epoch 6/20\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 0.0116 - accuracy: 0.9969 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1600/1600 [==============================] - 18s 11ms/step - loss: 0.0558 - accuracy: 0.9775 - val_loss: 1.2139 - val_accuracy: 0.5725\n",
      "Epoch 8/20\n",
      "1600/1600 [==============================] - 17s 11ms/step - loss: 0.0350 - accuracy: 0.9875 - val_loss: 0.0125 - val_accuracy: 0.9975\n",
      "Epoch 9/20\n",
      "1600/1600 [==============================] - 17s 10ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0134 - val_accuracy: 0.9950\n",
      "Epoch 10/20\n",
      "1600/1600 [==============================] - 17s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9975\n",
      "Epoch 11/20\n",
      "1600/1600 [==============================] - 16s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.7481e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1600/1600 [==============================] - 16s 10ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1600/1600 [==============================] - 16s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9975\n",
      "Epoch 14/20\n",
      "1600/1600 [==============================] - 16s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9950\n",
      "Epoch 15/20\n",
      "1600/1600 [==============================] - 18s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9975\n",
      "Epoch 16/20\n",
      "1600/1600 [==============================] - 19s 12ms/step - loss: 6.6617e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1600/1600 [==============================] - 18s 11ms/step - loss: 5.6072e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9975\n",
      "Epoch 18/20\n",
      "1600/1600 [==============================] - 17s 11ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 3.5638e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1600/1600 [==============================] - 17s 10ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1600/1600 [==============================] - 16s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.6422e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSpyder Editor\\n\\nThis is a temporary script file.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D\n",
    "from keras import backend as bk\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers import Activation\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "def piecewise5(X):\n",
    "                   return bk.switch(X < -0.6, (0.01 * X ),\n",
    "                                   bk.switch(X < -0.2, (0.2 * X ),\n",
    "                                            bk.switch(X < 0.2, (1 * X ),\n",
    "                                                     bk.switch(X < 0.6, (1.5 * X ),\n",
    "                                                              bk.switch(X < 5, (3 * X ), (3 * X )))))) \n",
    "    \n",
    "get_custom_objects().update({'piecewise5': Activation(piecewise5)})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_shape=X_train.shape[1:]\n",
    "\n",
    "def custom_network(input_shape):\n",
    "\n",
    "#   model = Sequential()\n",
    "#   model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "#                  activation='relu',\n",
    "#                  input_shape=input_shape))\n",
    "#   model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#   model.add(Dropout(0.25))\n",
    "#   model.add(Flatten())\n",
    "#   model.add(Dense(128, activation='relu'))\n",
    "#   model.add(Dropout(0.5))\n",
    "#   model.add(Dense(num_classes, activation='softmax'))\n",
    "  \n",
    "  \n",
    "    input_img = Input(shape = (128, 16, 1))\n",
    "    \n",
    "    conv_1 = Conv2D(64, (3,3), padding='same', activation='piecewise5')(input_img)\n",
    "    block1_output = GlobalAveragePooling2D()(conv_1)\n",
    "    max_pool_1 = MaxPooling2D(pool_size=(2, 2),strides=(2,2), padding='same')(conv_1)\n",
    "    dropout_1 = Dropout(0.25)(max_pool_1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    conv_2 = Conv2D(64, (3,3), padding='same', activation='piecewise5')(dropout_1)\n",
    "    block2_output = GlobalAveragePooling2D()(conv_2)\n",
    "    max_pool_2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same')(conv_2)\n",
    "    dropout_2 = Dropout(0.01)(max_pool_2)\n",
    "    \n",
    "    \n",
    "    conv_3 = Conv2D(64, (3,3), padding='same', activation='piecewise5')(dropout_2)\n",
    "    block3_output = GlobalAveragePooling2D()(conv_3)\n",
    "    \n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "    output = keras.layers.concatenate([block1_output, block2_output, block3_output], axis = 1)\n",
    "#     output = Flatten()(output)\n",
    "    output = Dense(64,activation='piecewise5')(output)\n",
    "    out    = Dense(2, activation='softmax')(output)\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(inputs = input_img, outputs = out)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "#     input_img = Input(shape = (30, 30, 3))\n",
    "#     tower_1 = Conv2D(16, (1,1), padding='same', activation='elu')(input_img)\n",
    "#     tower_x = Conv2D(32, (3,3), padding='same', activation='elu')(tower_1)\n",
    "#     tower_y = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_x)\n",
    "#     tower_y = Dropout(0.1)(tower_y)\n",
    "#     tower_z = Conv2D(32, (1,1), padding='same', activation='elu')(tower_y)\n",
    "#     tower_a = Conv2D(32, (3,3), padding='same', activation='elu')(tower_z)\n",
    "#     tower_a = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_a)\n",
    "#     tower_a = Dropout(0.1)(tower_a)\n",
    "    \n",
    "  \n",
    "#     tower_2 = MaxPooling2D(pool_size=(4, 4), padding='same')(tower_x)\n",
    "#     tower_2 = Dropout(0.1)(tower_2)\n",
    "    \n",
    "#     tower_3 = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_z)\n",
    "#     tower_3 = Dropout(0.1)(tower_3)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     output = keras.layers.concatenate([tower_a, tower_2, tower_3], axis = 1)\n",
    "#     output = Flatten()(output)\n",
    "\n",
    "#     out    = Dense(43, activation='softmax')(output)\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     model = Model(inputs = input_img, outputs = out)\n",
    "#     print(model.summary())\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sgd=optimizers.SGD(lr=0.001, momentum=0.9, nesterov=False)\n",
    "model = custom_network(input_shape)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# #Compilation of the model\n",
    "# model.compile(\n",
    "#     loss='categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "#using ten epochs for the training and saving the accuracy for each epoch\n",
    "epochs = 20\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_val, y_val))\n",
    "\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# score2=model.evaluate(x_train,y_train, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "# print('Training loss:', score2[0])\n",
    "# print('Training accuracy:', score2[1])# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_flops(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(hist1.history['accuracy'])\n",
    "plt.plot(hist1.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim(0.93, 1.0)\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "# plt.plot(hist4.history['loss'])\n",
    "# plt.plot(hist4.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max average pool with bias\n",
    "\n",
    "\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(rate=0.25))\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(rate=0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(rate=0.5))\n",
    "# model.add(Dense(43, activation='softmax'))\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras import backend as bk\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras import initializers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def get_flops(model):\n",
    "    run_meta = tf.RunMetadata()\n",
    "    opts = tf.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "    # We use the Keras session graph in the call to the profiler.\n",
    "    flops = tf.profiler.profile(graph=bk.get_session().graph,\n",
    "                                run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "    return flops.total_float_ops\n",
    "\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "def piecewise5(X):\n",
    "                   return bk.switch(X < -0.6, (0.01 * X ),\n",
    "                                   bk.switch(X < -0.2, (0.2 * X ),\n",
    "                                            bk.switch(X < 0.2, (1 * X ),\n",
    "                                                     bk.switch(X < 0.6, (1.5 * X ),\n",
    "                                                              bk.switch(X < 5, (3 * X ), (3 * X )))))) \n",
    "    \n",
    "get_custom_objects().update({'piecewise5': Activation(piecewise5)})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_shape=X_train.shape[1:]\n",
    "\n",
    "def custom_network(input_shape):\n",
    "\n",
    "#   model = Sequential()\n",
    "#   model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "#                  activation='relu',\n",
    "#                  input_shape=input_shape))\n",
    "#   model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#   model.add(Dropout(0.25))\n",
    "#   model.add(Flatten())\n",
    "#   model.add(Dense(128, activation='relu'))\n",
    "#   model.add(Dropout(0.5))\n",
    "#   model.add(Dense(num_classes, activation='softmax'))\n",
    "  \n",
    "  \n",
    "#     input_img = Input(shape = (30, 30, 3))\n",
    "    \n",
    "#     conv_1 = Conv2D(64, (3,3), padding='same', activation='piecewise5')(input_img)\n",
    "#     block1_output = GlobalAveragePooling2D()(conv_1)\n",
    "#     max_pool_1 = MaxPooling2D(pool_size=(2, 2),strides=(2,2), padding='same')(conv_1)\n",
    "#     dropout_1 = Dropout(0.25)(max_pool_1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     conv_2 = Conv2D(64, (3,3), padding='same', activation='piecewise5')(dropout_1)\n",
    "#     block2_output = GlobalAveragePooling2D()(conv_2)\n",
    "#     max_pool_2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same')(conv_2)\n",
    "#     dropout_2 = Dropout(0.01)(max_pool_2)\n",
    "    \n",
    "    \n",
    "#     conv_3 = Conv2D(64, (3,3), padding='same', activation='piecewise5')(dropout_2)\n",
    "#     block3_output = GlobalAveragePooling2D()(conv_3)\n",
    "    \n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "#     output = keras.layers.concatenate([block1_output, block2_output, block3_output], axis = 1)\n",
    "# #     output = Flatten()(output)\n",
    "#     output = Dense(64,activation='piecewise5')(output)\n",
    "#     out    = Dense(43, activation='softmax')(output)\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     model = Model(inputs = input_img, outputs = out)\n",
    "#     print(model.summary())\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "    input_img = Input(shape = (30, 30, 3))\n",
    "    tower_1 = Conv2D(16, (1,1), padding='same', activation='elu')(input_img)\n",
    "    tower_x = Conv2D(32, (3,3), padding='same', activation='elu')(tower_1)\n",
    "    block1_output = GlobalAveragePooling2D()(tower_1)\n",
    "    tower_y = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_x)\n",
    "    tower_y = Dropout(0.1)(tower_y)\n",
    "    tower_z = Conv2D(32, (1,1), padding='same', activation='elu')(tower_y)\n",
    "    tower_a = Conv2D(32, (3,3), padding='same', activation='elu')(tower_z)\n",
    "    tower_a = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_a)\n",
    "    tower_a = Dropout(0.1)(tower_a)\n",
    "    \n",
    "  \n",
    "    tower_2 = AveragePooling2D(pool_size=(4, 4), padding='same')(tower_x)\n",
    "    tower_2 = Dropout(0.1)(tower_2)\n",
    "    \n",
    "    tower_3 = AveragePooling2D(pool_size=(2, 2), padding='same')(tower_z)\n",
    "    tower_3 = Dropout(0.1)(tower_3)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    output = keras.layers.concatenate([tower_a, tower_2, tower_3], axis = 1)\n",
    "    output = Flatten()(output)\n",
    "    out1 = keras.layers.concatenate([output,block1_output],axis=1)\n",
    "\n",
    "    out    = Dense(43, activation='softmax')(out1)\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(inputs = input_img, outputs = out)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sgd=optimizers.SGD(lr=0.001, momentum=0.9, nesterov=False)\n",
    "model = custom_network(input_shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# #Compilation of the model\n",
    "# model.compile(\n",
    "#     loss='categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy']\n",
    "# \n",
    "#using ten epochs for the training and saving the accuracy for each epoch\n",
    "epochs = 20\n",
    "hist2 = model.fit(X_train, y_train, batch_size=32, epochs=epochs,\n",
    "validation_data=(X_val, y_val))\n",
    "\n",
    "score3 = model.evaluate(X_val, y_val, verbose=0)\n",
    "score4=model.evaluate(X_train,y_train, verbose=0)\n",
    "print('Test loss:', score3[0])\n",
    "print('Test accuracy:', score3[1])\n",
    "print('Training loss:', score4[0])\n",
    "print('Training accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.subplot(211)\n",
    "plt.plot(hist1.history['accuracy'])\n",
    "plt.plot(hist2.history['accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim(0.98, 1.0)\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Triple Pool with Bias', 'Triple Pool without Bias'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(hist1.history['val_accuracy'])\n",
    "plt.plot(hist2.history['val_accuracy'])\n",
    "plt.title('Model Validation')\n",
    "plt.ylabel('Validation')\n",
    "plt.ylim(0.93, 1.0)\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Triple Pool with Bias', 'Triple Pool without Bias'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of the DNN model\n",
    "\n",
    "\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(rate=0.25))\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(rate=0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(rate=0.5))\n",
    "# model.add(Dense(43, activation='softmax'))\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D\n",
    "from keras import backend as bk\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers import Activation\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "def piecewise5(X):\n",
    "                   return bk.switch(X < -0.6, (0.01 * X ),\n",
    "                                   bk.switch(X < -0.2, (0.2 * X ),\n",
    "                                            bk.switch(X < 0.2, (1 * X ),\n",
    "                                                     bk.switch(X < 0.6, (1.5 * X ),\n",
    "                                                              bk.switch(X < 5, (3 * X ), (3 * X )))))) \n",
    "    \n",
    "get_custom_objects().update({'piecewise5': Activation(piecewise5)})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_shape=X_train.shape[1:]\n",
    "\n",
    "def custom_network(input_shape):\n",
    "\n",
    "#   model = Sequential()\n",
    "#   model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "#                  activation='relu',\n",
    "#                  input_shape=input_shape))\n",
    "#   model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#   model.add(Dropout(0.25))\n",
    "#   model.add(Flatten())\n",
    "#   model.add(Dense(128, activation='relu'))\n",
    "#   model.add(Dropout(0.5))\n",
    "#   model.add(Dense(num_classes, activation='softmax'))\n",
    "  \n",
    "  \n",
    "    input_img = Input(shape = (30, 30, 3))\n",
    "    \n",
    "    conv_1 = Conv2D(64, (3,3), padding='same', activation='piecewise5')(input_img)\n",
    "    block1_output = GlobalAveragePooling2D()(conv_1)\n",
    "    max_pool_1 = MaxPooling2D(pool_size=(2, 2),strides=(2,2), padding='same')(conv_1)\n",
    "    dropout_1 = Dropout(0.25)(max_pool_1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    conv_2 = Conv2D(128, (3,3), padding='same', activation='piecewise5')(dropout_1)\n",
    "    block2_output = GlobalAveragePooling2D()(conv_2)\n",
    "    max_pool_2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same')(conv_2)\n",
    "    dropout_2 = Dropout(0.01)(max_pool_2)\n",
    "    \n",
    "    \n",
    "    conv_3 = Conv2D(64, (3,3), padding='same', activation='piecewise5')(dropout_2)\n",
    "    block3_output = GlobalAveragePooling2D()(conv_3)\n",
    "    max_pool_3 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same')(conv_3)\n",
    "    dropout_3 = Dropout(0.01)(max_pool_3)\n",
    "    \n",
    "    \n",
    "    conv_4 = Conv2D(128, (3,3), padding='same', activation='piecewise5')(dropout_3)\n",
    "    block4_output = GlobalAveragePooling2D()(conv_4)\n",
    "    max_pool_4 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same')(conv_4)\n",
    "    dropout_4 = Dropout(0.01)(max_pool_4)\n",
    "    \n",
    "    \n",
    "    conv_5 = Conv2D(64, (3,3), padding='same', activation='piecewise5')(dropout_4)\n",
    "    block5_output = GlobalAveragePooling2D()(conv_5)\n",
    "    max_pool_5 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same')(conv_5)\n",
    "    dropout_5 = Dropout(0.01)(max_pool_5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    conv_6 = Conv2D(128, (3,3), padding='same', activation='piecewise5')(dropout_5)\n",
    "    block6_output = GlobalAveragePooling2D()(conv_6)\n",
    "    \n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "    output = keras.layers.concatenate([block1_output, block2_output, block3_output,block4_output,block5_output, block6_output ], axis = 1)\n",
    "#     output = Flatten()(output)\n",
    "    output = Dense(64,activation='piecewise5')(output)\n",
    "    out    = Dense(43, activation='softmax')(output)\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(inputs = input_img, outputs = out)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "#     input_img = Input(shape = (30, 30, 3))\n",
    "#     tower_1 = Conv2D(16, (1,1), padding='same', activation='elu')(input_img)\n",
    "#     tower_x = Conv2D(32, (3,3), padding='same', activation='elu')(tower_1)\n",
    "#     tower_y = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_x)\n",
    "#     tower_y = Dropout(0.1)(tower_y)\n",
    "#     tower_z = Conv2D(32, (1,1), padding='same', activation='elu')(tower_y)\n",
    "#     tower_a = Conv2D(32, (3,3), padding='same', activation='elu')(tower_z)\n",
    "#     tower_a = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_a)\n",
    "#     tower_a = Dropout(0.1)(tower_a)\n",
    "    \n",
    "  \n",
    "#     tower_2 = MaxPooling2D(pool_size=(4, 4), padding='same')(tower_x)\n",
    "#     tower_2 = Dropout(0.1)(tower_2)\n",
    "    \n",
    "#     tower_3 = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_z)\n",
    "#     tower_3 = Dropout(0.1)(tower_3)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     output = keras.layers.concatenate([tower_a, tower_2, tower_3], axis = 1)\n",
    "#     output = Flatten()(output)\n",
    "\n",
    "#     out    = Dense(43, activation='softmax')(output)\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     model = Model(inputs = input_img, outputs = out)\n",
    "#     print(model.summary())\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sgd=optimizers.SGD(lr=0.001, momentum=0.9, nesterov=False)\n",
    "model = custom_network(input_shape)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# #Compilation of the model\n",
    "# model.compile(\n",
    "#     loss='categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "#using ten epochs for the training and saving the accuracy for each epoch\n",
    "epochs = 20\n",
    "hist3 = model.fit(X_train, y_train, batch_size=32, epochs=epochs,\n",
    "validation_data=(X_val, y_val))\n",
    "\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# score2=model.evaluate(x_train,y_train, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "# print('Training loss:', score2[0])\n",
    "# print('Training accuracy:', score2[1])\n",
    "\n",
    "\n",
    "score5 = model.evaluate(X_val, y_val, verbose=0)\n",
    "score6=model.evaluate(X_train,y_train, verbose=0)\n",
    "print('Test loss:', score6[0])\n",
    "print('Test accuracy:', score6[1])\n",
    "print('Training loss:', score6[0])\n",
    "print('Training accuracy:', score6[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(211)\n",
    "plt.plot(hist1.history['accuracy'])\n",
    "plt.plot(hist3.history['accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim(0.98, 1.0)\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Triple Pool with Bias', 'Triple Pool without Bias'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max average pool with bias and adam optimizer\n",
    "\n",
    "\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(rate=0.25))\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(rate=0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(rate=0.5))\n",
    "# model.add(Dense(43, activation='softmax'))\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D, AveragePooling2D\n",
    "from keras import backend as bk\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras import initializers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def get_flops(model):\n",
    "    run_meta = tf.RunMetadata()\n",
    "    opts = tf.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "    # We use the Keras session graph in the call to the profiler.\n",
    "    flops = tf.profiler.profile(graph=bk.get_session().graph,\n",
    "                                run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "    return flops.total_float_ops\n",
    "\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "def piecewise5(X):\n",
    "                   return bk.switch(X < -0.6, (0.01 * X ),\n",
    "                                   bk.switch(X < -0.2, (0.2 * X ),\n",
    "                                            bk.switch(X < 0.2, (1 * X ),\n",
    "                                                     bk.switch(X < 0.6, (1.5 * X ),\n",
    "                                                              bk.switch(X < 5, (3 * X ), (3 * X )))))) \n",
    "    \n",
    "get_custom_objects().update({'piecewise5': Activation(piecewise5)})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_shape=X_train.shape[1:]\n",
    "\n",
    "def custom_network(input_shape):\n",
    "\n",
    "#   model = Sequential()\n",
    "#   model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "#                  activation='relu',\n",
    "#                  input_shape=input_shape))\n",
    "#   model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#   model.add(Dropout(0.25))\n",
    "#   model.add(Flatten())\n",
    "#   model.add(Dense(128, activation='relu'))\n",
    "#   model.add(Dropout(0.5))\n",
    "#   model.add(Dense(num_classes, activation='softmax'))\n",
    "  \n",
    "  \n",
    "#     input_img = Input(shape = (30, 30, 3))\n",
    "    \n",
    "#     conv_1 = Conv2D(64, (3,3), padding='same', activation='piecewise5')(input_img)\n",
    "#     block1_output = GlobalAveragePooling2D()(conv_1)\n",
    "#     max_pool_1 = MaxPooling2D(pool_size=(2, 2),strides=(2,2), padding='same')(conv_1)\n",
    "#     dropout_1 = Dropout(0.25)(max_pool_1)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     conv_2 = Conv2D(64, (3,3), padding='same', activation='piecewise5')(dropout_1)\n",
    "#     block2_output = GlobalAveragePooling2D()(conv_2)\n",
    "#     max_pool_2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same')(conv_2)\n",
    "#     dropout_2 = Dropout(0.01)(max_pool_2)\n",
    "    \n",
    "    \n",
    "#     conv_3 = Conv2D(64, (3,3), padding='same', activation='piecewise5')(dropout_2)\n",
    "#     block3_output = GlobalAveragePooling2D()(conv_3)\n",
    "    \n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "#     output = keras.layers.concatenate([block1_output, block2_output, block3_output], axis = 1)\n",
    "# #     output = Flatten()(output)\n",
    "#     output = Dense(64,activation='piecewise5')(output)\n",
    "#     out    = Dense(43, activation='softmax')(output)\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     model = Model(inputs = input_img, outputs = out)\n",
    "#     print(model.summary())\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "    input_img = Input(shape = (30, 30, 3))\n",
    "    tower_1 = Conv2D(16, (1,1), padding='same', activation='elu', bias_initializer=initializers.Constant(.1))(input_img)\n",
    "    tower_x = Conv2D(32, (3,3), padding='same', activation='elu', bias_initializer=initializers.Constant(.1))(tower_1)\n",
    "    block1_output = GlobalAveragePooling2D()(tower_1)\n",
    "    tower_y = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_x)\n",
    "    tower_y = Dropout(0.1)(tower_y)\n",
    "    tower_z = Conv2D(32, (1,1), padding='same', activation='elu', bias_initializer=initializers.Constant(.1))(tower_y)\n",
    "    tower_a = Conv2D(32, (3,3), padding='same', activation='elu', bias_initializer=initializers.Constant(.1))(tower_z)\n",
    "    tower_a = MaxPooling2D(pool_size=(2, 2), padding='same')(tower_a)\n",
    "    tower_a = Dropout(0.1)(tower_a)\n",
    "    \n",
    "  \n",
    "    tower_2 = AveragePooling2D(pool_size=(4, 4), padding='same')(tower_x)\n",
    "    tower_2 = Dropout(0.1)(tower_2)\n",
    "    \n",
    "    tower_3 = AveragePooling2D(pool_size=(2, 2), padding='same')(tower_z)\n",
    "    tower_3 = Dropout(0.1)(tower_3)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    output = keras.layers.concatenate([tower_a, tower_2, tower_3], axis = 1)\n",
    "    output = Flatten()(output)\n",
    "    out1 = keras.layers.concatenate([output,block1_output],axis=1)\n",
    "\n",
    "    out    = Dense(43, activation='softmax')(out1)\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(inputs = input_img, outputs = out)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sgd=optimizers.SGD(lr=0.001, momentum=0.9, nesterov=False)\n",
    "model = custom_network(input_shape)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# #Compilation of the model\n",
    "# model.compile(\n",
    "#     loss='categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy']\n",
    "# \n",
    "#using ten epochs for the training and saving the accuracy for each epoch\n",
    "epochs = 20\n",
    "hist4 = model.fit(X_train, y_train, batch_size=32, epochs=epochs,\n",
    "validation_data=(X_val, y_val))\n",
    "\n",
    "score7 = model.evaluate(X_val, y_val, verbose=0)\n",
    "score8=model.evaluate(X_train,y_train, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Training loss:', score2[0])\n",
    "print('Training accuracy:', score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(211)\n",
    "# plt.plot(hist1.history['accuracy'])\n",
    "plt.plot(hist3.history['accuracy'])\n",
    "plt.plot(hist4.history['accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim(0.98, 1.0)\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Triple Pool with Bias SGD', 'GC Net without bias','Triple Pool with Bias Adam'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='accurate.png',show_shapes=True, show_layer_names=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max pool with Bias\n",
    "\n",
    "\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(rate=0.25))\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(rate=0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(rate=0.5))\n",
    "# model.add(Dense(43, activation='softmax'))\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D\n",
    "from keras import backend as bk\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras import initializers\n",
    "\n",
    "\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def get_flops(model):\n",
    "    run_meta = tf.RunMetadata()\n",
    "    opts = tf.profiler.ProfileOptionBuilder.float_operation()\n",
    "\n",
    "    # We use the Keras session graph in the call to the profiler.\n",
    "    flops = tf.profiler.profile(graph=bk.get_session().graph,\n",
    "                                run_meta=run_meta, cmd='op', options=opts)\n",
    "\n",
    "    return flops.total_float_ops\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "def piecewise5(X):\n",
    "                   return bk.switch(X < -0.6, (0.01 * X ),\n",
    "                                   bk.switch(X < -0.2, (0.2 * X ),\n",
    "                                            bk.switch(X < 0.2, (1 * X ),\n",
    "                                                     bk.switch(X < 0.6, (1.5 * X ),\n",
    "                                                              bk.switch(X < 5, (3 * X ), (3 * X )))))) \n",
    "    \n",
    "get_custom_objects().update({'piecewise5': Activation(piecewise5)})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_shape=X_train.shape[1:]\n",
    "\n",
    "def custom_network(input_shape):\n",
    "\n",
    "    input_img = Input(shape = (30, 30, 3))\n",
    "    x=Conv2D(64,(3,3), padding='same', activation='relu')(input_img)\n",
    "    x=Conv2D(64,(3,3), padding='same', activation='relu')(x)\n",
    "    x=MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "    \n",
    "    \n",
    "    x=Conv2D(128,(3,3),padding='same',activation='relu')(x)\n",
    "    x=Conv2D(128,(3,3),padding='same',activation='relu')(x)\n",
    "    x=MaxPooling2D(pool_size=(2,2), strides=(2,2),padding='same')(x)\n",
    "    \n",
    "    \n",
    "    x=Conv2D(256,(3,3),padding='same',activation='relu')(x)\n",
    "    x=Conv2D(256,(3,3),padding='same',activation='relu')(x)\n",
    "    x=Conv2D(256,(3,3),padding='same',activation='relu')(x)\n",
    "    x=MaxPooling2D(pool_size=(2,2), strides=(2,2),padding='same')(x)\n",
    "             \n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512,activation='piecewise5')(x)\n",
    "    x = Dense(43, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs = input_img, outputs = x)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sgd=optimizers.SGD(lr=0.001, momentum=0.9, nesterov=False)\n",
    "# model = custom_network(input_shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# # add a global spatial average pooling layer\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# # let's add a fully-connected layer\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# # and a logistic layer -- let's say we have 200 classes\n",
    "# predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# # this is the model we will train\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "input_img = Input(shape=(30, 30, 3))\n",
    "# Generate a model with all layers (with top)\n",
    "resnet = ResNet50(input_tensor=input_img, include_top=True)\n",
    "\n",
    "#Add a layer where input is the output of the  second last layer \n",
    "x = Dense(43, activation='softmax', name='predictions')(resnet.layers[-2].output)\n",
    "\n",
    "#Then create the corresponding model \n",
    "model = Model(input=resnet.input, output=x)\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "# this could also be the output a different Keras model or layer\n",
    "# input_img = Input(shape=(30, 30, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "\n",
    "# base_model = ResNet50(input_tensor=input_img)\n",
    "# x = base_model.output\n",
    "# predictions = Dense(43, activation='softmax')(x)\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# # model = ResNet50(input_shape)\n",
    "# # base_model = ResNet50(input_shape)\n",
    "# # model = Model(inputs=base_model.input)\n",
    "\n",
    "\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# #Compilation of the model\n",
    "# model.compile(\n",
    "#     loss='categorical_crossentropy', \n",
    "#     optimizer='adam', \n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "#using ten epochs for the training and saving the accuracy for each epoch\n",
    "epochs = 20\n",
    "hist5 = model.fit(X_train, y_train, batch_size=32, epochs=epochs,\n",
    "validation_data=(X_val, y_val))\n",
    "\n",
    "\n",
    "\n",
    "score7 = model.evaluate(X_val, y_val, verbose=0)\n",
    "score8=model.evaluate(X_train,y_train, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Training loss:', score2[0])\n",
    "print('Training accuracy:', score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
